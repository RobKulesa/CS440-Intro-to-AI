%! Author = Robert Kulesa, Daniel Liu, Michael Li
%! Date = 10/5/2021

% Preamble
\documentclass[11pt]{article}

% Packages
\usepackage{amsmath}

% Document
\begin{document}
    \begin{titlepage}
        \begin{center}
            \vspace*{1cm}

            \Huge
            \textbf{Fast Trajectory Replanning}

            \vspace{0.5cm}
            \LARGE
            Assignment 1

            \vspace{1cm}

            \textbf{Robert Kulesa, Michael Li, Daniel Liu}

            \vfill


            \vspace{0.8cm}

            \Large
            CS440 Fall 2021\\
            Professor Boularias\\
            Rutgers University - New Brunswick\\
            October 15, 2021

        \end{center}
    \end{titlepage}
    \begin{center}
        \Large
        \textbf{Part 1 - Understanding the methods}
    \end{center}
    \normalsize
    \begin{enumerate}
        \item[a)] The agent moves east, because the unblocked,
        unvisited neighbor with the lowest cost $f(x) = g(x) + h(x)$ is the eastern neighbor.
        Using manhattan distance as $h(x)$, the eastern neighbor has $f(x) = 1 + 2 = 3$,
        whereas the northern neighbor has $f(x) = 1 + 4 = 5$.
        Therefore, the eastern neighbor is selected, and the agent explores the eastern cell.
        \item[b)] second item
    \end{enumerate}
    
    
    \begin{center}
        \Large
        \textbf{Part 2 - The Effects of Ties}
    \end{center}
    %insert explanation here
    
    \begin{center}
        \Large
        \textbf{Part 3 - Forward vs. Backward}
    \end{center}
    %insert explanation here
    
    \begin{center}
        \Large
        \textbf{Part 4 - Heuristics in the Adaptive A*}
    \end{center}
    %insert explanation here
    a) Manhattan distance is defined as the sum of the magnitudes of the difference between the x and y coordinates of a given start and end point. A heuristic is considered consistent if its estimate is always less than or equal to the estimated distance from any neighbouring node to the goal, plus the cost of reaching that neighbour. This can be represented by the following equation:\\
    \centerline{$h(N) \le c(N, P) + h(P)$ where:} \\
    $N$ is a node in the gridworld \\
    $P$ is a neighbor of N\\
    $h(N)$ is the estimated cost from N to the goal\\
    $h(P)$ is the estimated cost from P to the goal\\
    $c(N,P)$ is the cost of reaching node P from N\\
    
    Assuming A* is inconsistent in a gridworld where only cardinal movement is allowed:\\
    \centerline{$h(N) > c(N, P) + h(P)$}\\
    
    Shifting $h(P)$ to the right side of the equation:\\
    \centerline{$h(N) - h(P) > c(N, P)$}\\
    
    In a gridworld where only cardinal movement is allowed, h(N)-h(P) is equal to the Manhattan distance between N and P:\\
    \centerline{$|X\textsubscript{N}-X\textsubscript{P}| + |Y\textsubscript{N}-Y\textsubscript{P}| > c(N, P)$}\\
    
    The only way the Manhattan distance between N and P could be greater than c(N,P) would be if the agent were to make a diagonal movement. However, since the agent in our gridworld is restricted to cardinal movement, this move is impossible. Thus, Manhattan distance is consistent in gridworlds in which the agent can only move in cardinal directions.\\

    b) Adaptive A* uses the following heuristic:\\
    \centerline{$h(N) = g(G) - g(N)$ where}
    $g(N)$ is the distance between the start start and the current node\\
    $g(G)$ is the distance between the start start and the goal state\\
    
    Substituting this into the consistent heuristic function results in the following equation\\
    \centerline{$g(G) - g(N) \le c(N,P) + g(G) - g(P)$}\\
    
    Removing g(G) from both sides of the equation:\\
    \centerline{$g(P) - g(N) \le c(N,P)$}\\
    
    Given that g(P) and g(N) is computed with Manhattan distance\\
    \centerline{$|X\textsubscript{P}-X\textsubscript{N}| + |Y\textsubscript{P}-Y\textsubscript{N}| \le c(N, P)$}\\
    
    Since adaptive A* is being conducted in a gridworld where only cardinal movement is possible, the cost of movement between nodes N and P can never exceed the Manhattan distance between N and P. Thus, adaptive A* maintains the consistency of the h-values.
    
    \begin{center}
        \Large
        \textbf{Part 5 - Repeated Forward A* vs. Adaptive A*}
    \end{center}
    %insert explanation here
    
    
    \begin{center}
        \Large
        \textbf{Part 6 - Statistical Significance}
    \end{center}
    %insert explanation here
    a) 
    %Approach where we utilize a null hypothesis test - I think this method is used to compare baseline performance + different algorithm performance in regards to the baseline
    We can perform a statistical null hypothesis test on Question 5, Repeated Forward A* vs. Adaptive A*. By utilizing a t-test, we can compare these two machine learning algorithms and evaluate whether there is a true different in mean performance between them. We will be presented with a statistical confidence interval in which we believe that a perceived difference is observed between the two algorithms. While performing a null hypothesis test, we assume as our null hypothesis, that performance between the two algorithms are equal, and that there are no differences. With a t-test, we calculate the p-value of our test, which will indicate whether or not we should reject or fail to reject our null hypohtesis. We have to designate a p-value threshold (most of the time, 0.05 is used) - if our p-value is below this threshold, we reject the null hypothesis and conclude that the difference between the two algorithms is significant and one algorithm runs more efficiently. However, if our p-value is above this threshold, we will be unable to draw any conclusions from our data - all differences observed will not be significant. 
    %Approach where we utilize a statistical hypothesis test with k-fold cross validation
    We can perform a statistical hypothesis test on Question 5, Repeated Forward A* vs. Adaptive A*. By utilizing k-fold cross validation, we can train and test k models and collect their data, utilizing their individual means as evidence for algorithmical performance. To perform this test, we would split our sample for Repeat Forward A* as well as Adaptive A* into k-folds each, and train k models per algorithm. We will then get data from these trials, and utilize a statistical test to identify and observe if any difference between our trial data between the two algorithms are statistically significant. Typically, for machine learning algorithms, a 5 times 2-fold cross validation technique is used. In this case, we would partition our original sample into 2 equal sized subsamples. Then, the cross-validation process is repeated for 2 folds. Each k subsample is only utilized once. Following this, the results from the trial can be combined to form an average estimate. Then, the experiment is repeated 5 times. At the end, all the data is combined to form a final average estimate. This data from the two algorithms are then used in a t-test to idenitfy if there is any significant differences. If so, then we will be able to conclude that the difference in performance between the two algorithms is indeed stiatically significant. By performing these statistical hypothesis tests, we can have higher confidence that performance differences between two search algorithms are actually systematic in nature, and not due to sampling noise.
    
    
\end{document}
